{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDCC Project - Auto ML dataset preparation",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvtap/BDCC/blob/main/BDCC_Project_Auto_ML_dataset_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwWx1bZxThor"
      },
      "source": [
        "# Setup spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQboAxCeCcLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5758f4-f472-4e17-ad55-daa45db4a321"
      },
      "source": [
        "def setupSpark():\n",
        "  # Spark needs to run with Java 8 ... \n",
        "  !pip install -q findspark\n",
        "  !apt-get install openjdk-8-jdk-headless > /dev/null\n",
        "  !echo 2 | update-alternatives --config java > /dev/null\n",
        "  !java -version\n",
        "  import os, findspark\n",
        "  os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "  # !echo JAVA_HOME=$JAVA_HOME\n",
        "  !pip install -q pyspark\n",
        "  findspark.init(spark_home='/usr/local/lib/python3.7/dist-packages/pyspark')\n",
        "  !pyspark --version\n",
        "\n",
        "setupSpark()\n",
        "\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "    \n",
        "spark = SparkSession\\\n",
        "        .builder\\\n",
        "        .master('local[*]')\\\n",
        "        .getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_282\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_282-8u282-b08-0ubuntu1~18.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.282-b08, mixed mode)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 77kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 57.5MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.1.1\n",
            "      /_/\n",
            "                        \n",
            "Using Scala version 2.12.10, OpenJDK 64-Bit Server VM, 1.8.0_282\n",
            "Branch HEAD\n",
            "Compiled by user ubuntu on 2021-02-22T01:33:19Z\n",
            "Revision 1d550c4e90275ab418b9161925049239227f3dc9\n",
            "Url https://github.com/apache/spark\n",
            "Type --help for more information.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSb3XuVyTrxV"
      },
      "source": [
        "# Connect to Google Cloud \n",
        "\n",
        "__You need to set the `PROJECT_ID` variable.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hH71VgtCjXc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "494533c1-3e87-4550-c82b-6f6d3a72f76b"
      },
      "source": [
        "PROJECT_ID = 'bdcc-project1-309010' \n",
        "BUCKET_URI = 'gs://bdcc_open_images_dataset'\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project {PROJECT_ID}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwepc5LkUCL7"
      },
      "source": [
        "# Get necessary data\n",
        "\n",
        "This will fetch files that contain the same data as in the BigQuery tables we use for the project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_Sf0YPqCw30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "170bb94c-9b51-460c-e941-830fce0461cb"
      },
      "source": [
        "!gsutil cp {BUCKET_URI}/data/classes.csv .\n",
        "!gsutil cp {BUCKET_URI}/data/image-labels.csv .\n",
        "!head classes.csv\n",
        "!head image-labels.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://bdcc_open_images_dataset/data/classes.csv...\n",
            "/ [1 files][ 11.8 KiB/ 11.8 KiB]                                                \n",
            "Operation completed over 1 objects/11.8 KiB.                                     \n",
            "Copying gs://bdcc_open_images_dataset/data/image-labels.csv...\n",
            "\\ [1 files][ 10.9 MiB/ 10.9 MiB]                                                \n",
            "Operation completed over 1 objects/10.9 MiB.                                     \n",
            "Label,Description\n",
            "/m/011k07,Tortoise\n",
            "/m/011q46kg,Container\n",
            "/m/012074,Magpie\n",
            "/m/0120dh,Sea turtle\n",
            "/m/01226z,Football\n",
            "/m/012n7d,Ambulance\n",
            "/m/012w5l,Ladder\n",
            "/m/012xff,Toothbrush\n",
            "/m/012ysf,Syringe\n",
            "ImageId,Label\n",
            "000026e7ee790996,/m/07j7r\n",
            "000026e7ee790996,/m/05s2s\n",
            "000062a39995e348,/m/015p6\n",
            "000062a39995e348,/m/05s2s\n",
            "0000c64e1253d68f,/m/0k4j\n",
            "0000c64e1253d68f,/m/07yv9\n",
            "000132c20b84269b,/m/03q69\n",
            "000132c20b84269b,/m/0dzct\n",
            "000132c20b84269b,/m/04hgtk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbNJk3w1US6I"
      },
      "source": [
        "# Initialize data frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7biE1P1OC6Ji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da4c38d-cfdb-448e-89e5-9762363023e8"
      },
      "source": [
        "classes = spark.read.csv('classes.csv',inferSchema=True,header=True)\n",
        "classes.cache()\n",
        "classes.createOrReplaceTempView('classes')\n",
        "classes.printSchema()\n",
        "classes.show()\n",
        "\n",
        "image_labels = spark.read.csv('image-labels.csv',inferSchema=True,header=True)\n",
        "image_labels.cache()\n",
        "image_labels.createOrReplaceTempView('image_labels')\n",
        "image_labels.printSchema()\n",
        "image_labels.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Label: string (nullable = true)\n",
            " |-- Description: string (nullable = true)\n",
            "\n",
            "+-----------+--------------------+\n",
            "|      Label|         Description|\n",
            "+-----------+--------------------+\n",
            "|  /m/011k07|            Tortoise|\n",
            "|/m/011q46kg|           Container|\n",
            "|  /m/012074|              Magpie|\n",
            "|  /m/0120dh|          Sea turtle|\n",
            "|  /m/01226z|            Football|\n",
            "|  /m/012n7d|           Ambulance|\n",
            "|  /m/012w5l|              Ladder|\n",
            "|  /m/012xff|          Toothbrush|\n",
            "|  /m/012ysf|             Syringe|\n",
            "|  /m/0130jx|                Sink|\n",
            "|  /m/0138tl|                 Toy|\n",
            "|  /m/013y1f|Organ (Musical In...|\n",
            "|  /m/01432t|       Cassette deck|\n",
            "|  /m/014j1m|               Apple|\n",
            "|  /m/014sv8|           Human eye|\n",
            "|  /m/014trl|           Cosmetics|\n",
            "|  /m/014y4n|              Paddle|\n",
            "|  /m/0152hh|             Snowman|\n",
            "|   /m/01599|                Beer|\n",
            "|   /m/01_5g|          Chopsticks|\n",
            "+-----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- ImageId: string (nullable = true)\n",
            " |-- Label: string (nullable = true)\n",
            "\n",
            "+----------------+----------+\n",
            "|         ImageId|     Label|\n",
            "+----------------+----------+\n",
            "|000026e7ee790996|  /m/07j7r|\n",
            "|000026e7ee790996|  /m/05s2s|\n",
            "|000062a39995e348|  /m/015p6|\n",
            "|000062a39995e348|  /m/05s2s|\n",
            "|0000c64e1253d68f|   /m/0k4j|\n",
            "|0000c64e1253d68f|  /m/07yv9|\n",
            "|000132c20b84269b|  /m/03q69|\n",
            "|000132c20b84269b|  /m/0dzct|\n",
            "|000132c20b84269b| /m/04hgtk|\n",
            "|000132c20b84269b|/m/02p0tk3|\n",
            "|000132c20b84269b|  /m/0cgh4|\n",
            "|000132c20b84269b|/m/0283dt1|\n",
            "|000132c20b84269b| /m/01g317|\n",
            "|000132c20b84269b| /m/05r655|\n",
            "|000132c20b84269b|  /m/0dzf4|\n",
            "|000132c20b84269b|/m/03bt1vf|\n",
            "|000132c20b84269b|  /m/09j2d|\n",
            "|0002ab0af02e4a77|  /m/0k0pj|\n",
            "|0002ab0af02e4a77|  /m/07j7r|\n",
            "|0002ab0af02e4a77| /m/0c9ph5|\n",
            "+----------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6DvT1_1UtVw"
      },
      "source": [
        "# Define the classes for your model.\n",
        "\n",
        "Change __`CLASSES`__ to the image classes you want. \n",
        "\n",
        "See the project description for instructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqkpwniWYCQL"
      },
      "source": [
        "CLASSES =[\n",
        "          ('Aircraft',), \n",
        "          ('Bicycle',), \n",
        "          ('Boat',),  \n",
        "          ('Bus',), \n",
        "          ('Car',),  \n",
        "          ('Train',), \n",
        "          ('Helicopter',), \n",
        "          ('Motorcycle',), \n",
        "          ('Truck',), \n",
        "          ('Skateboard',)\n",
        "]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpL3c83dU1M5",
        "outputId": "f7c45f05-2bbd-4ee8-9722-dc7f013b6dc8"
      },
      "source": [
        "class_labels = spark.createDataFrame(data=CLASSES,schema=['Description'])\n",
        "class_labels.cache()\n",
        "class_labels.createOrReplaceTempView('class_labels')\n",
        "class_labels.printSchema()\n",
        "class_labels.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Description: string (nullable = true)\n",
            "\n",
            "+-----------+\n",
            "|Description|\n",
            "+-----------+\n",
            "|   Aircraft|\n",
            "|    Bicycle|\n",
            "|       Boat|\n",
            "|        Bus|\n",
            "|        Car|\n",
            "|      Train|\n",
            "| Helicopter|\n",
            "| Motorcycle|\n",
            "|      Truck|\n",
            "| Skateboard|\n",
            "+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAlb6w_rVOBm"
      },
      "source": [
        "# Define the data set you want using Spark \n",
        "\n",
        "Now it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnowCeYhVsZF"
      },
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, col"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mluECQJSOa-q"
      },
      "source": [
        "getimages = \\\n",
        "  image_labels.join(classes,'Label')\\\n",
        "  .join(class_labels,'Description')\\\n",
        "  .select('ImageId','Description')\\\n",
        "  .orderBy('Description')\\"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5buLo-fi6v7"
      },
      "source": [
        "window = \\\n",
        "  Window  \\\n",
        "  .partitionBy(getimages['Description'])\\\n",
        "  .orderBy(getimages['ImageId'])"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmeL0H9HlB_l"
      },
      "source": [
        "final = \\\n",
        "  getimages.select('*', rank().over(window).alias('rank')) \\\n",
        "  .filter(col('rank') <= 100)\\\n",
        "  .toPandas()"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4th05iePkkH0"
      },
      "source": [
        "final = final.drop(columns='rank')"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N80D1O1tYct"
      },
      "source": [
        "final['train/test']=''"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtXGyDO2v7K6"
      },
      "source": [
        "classes_list =[\n",
        "          'Aircraft', \n",
        "          'Bicycle', \n",
        "          'Boat',  \n",
        "          'Bus', \n",
        "          'Car',\n",
        "          'Helicopter',  \n",
        "          'Motorcycle',\n",
        "          'Skateboard',\n",
        "          'Train',          \n",
        "          'Truck'\n",
        "]"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcfXpsnjvFMV"
      },
      "source": [
        "for i in range(len(classes_list)):\n",
        "    final.loc[i*100:i*100+79,'train/test'][final['Description']==classes_list[i]] = 'TRAIN'\n",
        "    final.loc[i*100+80:i*100+89,'train/test'][final['Description']==classes_list[i]] = 'VALIDATION'\n",
        "    final.loc[i*100+90:i*100+99,'train/test'][final['Description']==classes_list[i]] = 'TEST'"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9w7QpK453Zk"
      },
      "source": [
        "cols = final.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "final = final[cols]"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecYf_YSEVu06"
      },
      "source": [
        "# Put the data in a convenient bucket\n",
        "\n",
        "Now upload the CSV file describing the file and __only__ the necessary images to the bucket you'll use with AutoML.\n",
        "\n",
        "__Note__: the bucket must be created using a __Regional__ location setting. Choose __us-central1__ for example. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLVjlM78RiEQ"
      },
      "source": [
        "MY_AUTOML_BUCKET='TODO'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEa4HDh6XvKN"
      },
      "source": [
        "# TODO upload CSV and image file"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}