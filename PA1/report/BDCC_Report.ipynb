{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71lRx2zFg-kl"
   },
   "source": [
    "# Big Data and Cloud Computing - Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikowvKMm38eW"
   },
   "source": [
    "Authors: David Maia (up201908521) and Miguel Tavares (up200902937)\n",
    "\n",
    "GCP Project ID: bdcc-project1-309010 \n",
    "\n",
    "URL: https://bdcc-project1-309010.ew.r.appspot.com/\n",
    "\n",
    "URL (deployed using docker): https://image-xhfxku6nlq-uc.a.run.app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6koXnpP6-L-"
   },
   "source": [
    "# **Endpoints** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXfdl1BzUaYp"
   },
   "source": [
    "**image_search_multiple**\n",
    "\n",
    "This endpoint has an objective of receiving mulitple descriptions of images and a limit to the number of images presented. This query would select the ImageID (identifier of each image) and an array of its descriptions that belongs to the multiple descriptions requested. Ordering by the image with the most corresponding descriptions to the image with the least corresponding descriptions would give us the intended result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YcSXQzfY38F3"
   },
   "outputs": [],
   "source": [
    "results = BQ_CLIENT.query(\n",
    "    '''\n",
    "    SELECT ImageID, ARRAY_AGG(DISTINCT Description) AS classes, COUNT(DISTINCT Description) as c\n",
    "    FROM `bdcc21project.openimages.classes`\n",
    "    JOIN `bdcc21project.openimages.image_labels` USING(Label)\n",
    "    WHERE Description IN UNNEST({0})\n",
    "    GROUP BY ImageID\n",
    "    ORDER BY c desc \n",
    "    LIMIT {1}\n",
    "    '''.format(descriptions, image_limit)\n",
    "    ).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8ARBG-WUAUI"
   },
   "source": [
    "**relations**\n",
    "\n",
    "This endpoint allows to show all the possible relations between images. The query selects all relations and counts how many images have it, groups them and orders for alphabetic order (Relation name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMgMogq83iI4"
   },
   "outputs": [],
   "source": [
    "results = BQ_CLIENT.query(\n",
    "    '''\n",
    "        SELECT Relation, COUNT(*) AS NumImages\n",
    "        FROM `bdcc21project.openimages.relations`\n",
    "        GROUP BY Relation\n",
    "        ORDER BY Relation asc\n",
    "    ''').result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nkCT-GxUFF3"
   },
   "source": [
    "**relations_search**\n",
    "\n",
    "Search for images by relation (e.g. Girl plays Violin). This endpoint uses the operator LIKE so that if any of the three required parameters is not specified, it uses the default % and gives back the result as any. The query selects ImageId, Class1,\tRelation and Class2 by joining the table relations and the table classes twice (one for each class) when the relations and the classes are the requested ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Pb0BhAjUItT"
   },
   "outputs": [],
   "source": [
    "results = BQ_CLIENT.query(\n",
    "    '''\n",
    "    SELECT r.ImageId, c1.Description as Class1, r.Relation, c2.Description as Class2\n",
    "    FROM `bdcc21project.openimages.relations` r\n",
    "    JOIN `bdcc21project.openimages.classes` c1 ON (r.Label1=c1.Label)\n",
    "    JOIN `bdcc21project.openimages.classes` c2 ON (r.Label2=c2.Label)\n",
    "    WHERE r.Relation LIKE '{0}'\n",
    "    AND c1.Description LIKE '{1}'\n",
    "    AND c2.Description LIKE '{2}'\n",
    "    ORDER BY r.ImageId\n",
    "    LIMIT {3}\n",
    "    '''.format(relation, class1, class2, image_limit)\n",
    "    ).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMdQjgurUIIv"
   },
   "source": [
    "**image_info**\n",
    "\n",
    "Get information for a single image. Providing only the imageID in this endpoint should be presented a list of all relations and classes. To simplify two queries were used: one for the classes and another for the relations.<br />\n",
    "The first query selects all the Descriptions/Classes by joining two tables by the label and filtering by those that have the requested ImageId.<br />\n",
    "The second query is based on the relations_search being the only diference that we only filter by the ImageId requested and not the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jU078jLjUPWW"
   },
   "outputs": [],
   "source": [
    "results_classes = BQ_CLIENT.query(\n",
    "    '''\n",
    "        SELECT Description\n",
    "        FROM `bdcc21project.openimages.image_labels`\n",
    "        JOIN `bdcc21project.openimages.classes` USING(Label)\n",
    "        WHERE ImageId = '{0}' \n",
    "        ORDER BY Description asc \n",
    "    '''.format(image_id)\n",
    "    ).result()\n",
    "    \n",
    "    results_relations = BQ_CLIENT.query(\n",
    "    '''\n",
    "    SELECT c1.Description as Class1, r.Relation, c2.Description as Class2\n",
    "    FROM `bdcc21project.openimages.relations` r\n",
    "    JOIN `bdcc21project.openimages.classes` c1 ON (r.Label1=c1.Label)\n",
    "    JOIN `bdcc21project.openimages.classes` c2 ON (r.Label2=c2.Label)\n",
    "    WHERE r.ImageId = '{0}'\n",
    "    '''.format(image_id)\n",
    "    ).result()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZkRTX5BklQ0"
   },
   "source": [
    "# **TensorFlow dataset preparation notes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4w01nQZOIU1"
   },
   "source": [
    "For this part it was requested to choose 10 classes. Below we can see the list of the chosen 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BqkpwniWYCQL"
   },
   "outputs": [],
   "source": [
    "CLASSES =[\n",
    "          ('Aircraft',), \n",
    "          ('Bicycle',), \n",
    "          ('Boat',),  \n",
    "          ('Bus',), \n",
    "          ('Car',),  \n",
    "          ('Train',), \n",
    "          ('Helicopter',), \n",
    "          ('Motorcycle',), \n",
    "          ('Truck',), \n",
    "          ('Skateboard',)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c16zQqbOOZJO"
   },
   "source": [
    "This classes need to be in a dataframe so that we can use it after to select only images that belong to this classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpL3c83dU1M5"
   },
   "outputs": [],
   "source": [
    "class_labels = spark.createDataFrame(data=CLASSES,schema=['Description'])\n",
    "class_labels.cache()\n",
    "class_labels.createOrReplaceTempView('class_labels')\n",
    "class_labels.printSchema()\n",
    "class_labels.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATt6PLLOpxAP"
   },
   "source": [
    "First, we use pyspark to join the dataframes image_labels, classes and class_labels. Now this dataframe has all the images that belong to one of our 10 chosen classes.\n",
    "\n",
    "> To avoid a problem in AutoML which causes the dataset for each class to be much lower than 100 due to duplicates (e.g an image with a car and a boat can have both classes) is recommended to use *.dropDuplicates([\"ImageId\"])\\*. This way we ensure that each ImageID is our dataframe is unique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnowCeYhVsZF"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, col\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mluECQJSOa-q"
   },
   "outputs": [],
   "source": [
    "getimages = \\\n",
    "  image_labels.join(classes,'Label')\\\n",
    "  .join(class_labels,'Description')\\\n",
    "  .select('ImageId','Description')\\\n",
    "  .dropDuplicates([\"ImageId\"])\\\n",
    "  .orderBy('Description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-pkkxe7OofK"
   },
   "source": [
    "To select only 100 images for each class we use a Window partioned by Description and ordered by ImageId, this will cause the images to be ranked and separated by class. <br />\n",
    ".filter(col('rank') <= 100)\\ -> this filters the 100 first ImageId for each class <br />\n",
    "In the end we converted this to pandas dataframe for the simplicity of usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5buLo-fi6v7"
   },
   "outputs": [],
   "source": [
    "window = \\\n",
    "  Window  \\\n",
    "  .partitionBy(getimages['Description'])\\\n",
    "  .orderBy(getimages['ImageId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmeL0H9HlB_l"
   },
   "outputs": [],
   "source": [
    "final = \\\n",
    "  getimages.select('*', rank().over(window).alias('rank')) \\\n",
    "  .filter(col('rank') <= 100)\\\n",
    "  .toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqaO4iPvOpbZ"
   },
   "source": [
    "The column rank was only for the previous operation, can now be removed from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4th05iePkkH0"
   },
   "outputs": [],
   "source": [
    "final = final.drop(columns='rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYDFf7x8TnDX"
   },
   "source": [
    "We used this last part so that the output file could be exactly as request but this is optional for AutoML since the program already separates the dataset with the default distribution of 80% to train, 10% to validate and 10% to test.\n",
    "\n",
    "1.   Add a new column \"Train/Validation/Test\"\n",
    "2.   For each class divide the dataset and add the corresponding fase to the column according to the distribution of 80% to train, 10% to validate and 10% to test.\n",
    "3. Put the columns order as requested\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5N80D1O1tYct"
   },
   "outputs": [],
   "source": [
    "final['train/test']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PtXGyDO2v7K6"
   },
   "outputs": [],
   "source": [
    "classes_list =[\n",
    "          'Aircraft', \n",
    "          'Bicycle', \n",
    "          'Boat',  \n",
    "          'Bus', \n",
    "          'Car',\n",
    "          'Helicopter',  \n",
    "          'Motorcycle',\n",
    "          'Skateboard',\n",
    "          'Train',          \n",
    "          'Truck'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcfXpsnjvFMV"
   },
   "outputs": [],
   "source": [
    "for i in range(len(classes_list)):\n",
    "    final.loc[i*100:i*100+79,'train/test'][final['Description']==classes_list[i]] = 'TRAIN'\n",
    "    final.loc[i*100+80:i*100+89,'train/test'][final['Description']==classes_list[i]] = 'VALIDATION'\n",
    "    final.loc[i*100+90:i*100+99,'train/test'][final['Description']==classes_list[i]] = 'TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9w7QpK453Zk"
   },
   "outputs": [],
   "source": [
    "cols = final.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "final = final[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wevt-1PqqCmj"
   },
   "source": [
    "## **Move the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEeyimVvSZ1K"
   },
   "source": [
    "Define the bucket that will be used to storage the necessary images to build the TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLVjlM78RiEQ"
   },
   "outputs": [],
   "source": [
    "MY_AUTOML_BUCKET='gs://bddc_train_transport'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPqA_X6kTWBg"
   },
   "source": [
    "Copy all the necessary images to the bucket using a for cycle and the gsutil command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQMAQlgS7mMT"
   },
   "outputs": [],
   "source": [
    "for j in range(final.shape[0]):\n",
    "  id = final.loc[[j],['ImageId']].values\n",
    "  idf = id[0][0]\n",
    "  !gsutil cp {BUCKET_URI}/images/{idf}.jpg {MY_AUTOML_BUCKET}/img/\n",
    "  print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIEpCE-FPI91"
   },
   "source": [
    "The file will need the full path to container where the images are and not only the ImageID. To solve that issue we created a for loop to add the path to each ImageID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AW7Lt5m_aux"
   },
   "outputs": [],
   "source": [
    "finalML = final\n",
    "j=0\n",
    "for j in range(finalML.shape[0]):\n",
    "  id = finalML.loc[[j],['ImageId']].values\n",
    "  idf = id[0][0]\n",
    "  finalML.loc[[j],['ImageId']] = MY_AUTOML_BUCKET+'/img/'+idf+'.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXz33k4mOsU3"
   },
   "source": [
    "The pandas dataframe now needs to be exported to the final automl.csv file that we want to use, the command .to_csv allows to export in a simple way that doesn't export header or index so that the file is exactly as requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96shyi-VC8o4"
   },
   "outputs": [],
   "source": [
    "finalML.to_csv(MY_AUTOML_BUCKET+'/csv/automl.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A3VdJLrRA0g"
   },
   "source": [
    "## **Create TensorFlow model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAvoB72UTBP-"
   },
   "source": [
    "In https://console.cloud.google.com/vision/dashboard?project=bdcc-project1-309010, the dataset was created using the automl.csv. Then the model was created and exported as TensorFlow to the web application. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kn5nZsPsFiM6"
   },
   "source": [
    "## **Create Docker Image**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W435W6cJGKWX"
   },
   "source": [
    "Since AppEngine is enabled by containers internally, one way to deploy our application is using Docker. The first step is to create the Docker file which will define our environment.\n",
    "\n",
    "This environment was imported from google container registry [1] and then ran with a virtual environment of python 3 (the default is python 2). The final step was to define the packages required to run our application in *requirement.txt* file.\n",
    "\n",
    "The final instruction was to define the command to run a python application in a linux environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h1CzE0dPHpU"
   },
   "source": [
    "```shell\n",
    "FROM gcr.io/google-appengine/python\n",
    "RUN virtualenv /env -p python3\n",
    "ENV VIRTUAL_ENV /env\n",
    "ENV PATH /env/bin:$PATH\n",
    "ENV GOOGLE_CLOUD_PROJECT=bdcc-project1-309010\n",
    "ADD requirements.txt /app/requirements.txt\n",
    "RUN pip install -r /app/requirements.txt\n",
    "\n",
    "ADD . /app\n",
    "WORKDIR /app\n",
    "\n",
    "CMD [ \"python3\" , \"main.py\", \"--host=0.0.0.0\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4alrZCbrYmSp"
   },
   "source": [
    "[1] The gcr.io/google-appengine/python is a docker base image. This image can be used as the base image for running applications on Google App Engine Flexible, Google Kubernetes Engine, or any other Docker host.\n",
    "\n",
    "This image is based on Ubuntu Xenial and contains packages required to build most of the popular Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RaJzivXMC2z"
   },
   "source": [
    "Once the Docker file defined, we need to build and submit it to the cloud server (the image shall be available in container registry):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Q51zU1GMUzE"
   },
   "outputs": [],
   "source": [
    "gcloud builds submit --tag gcr.io/PROJECT_ID/IMAGE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjM5ohbUMkBx"
   },
   "source": [
    "The next step is to deploy it to cloud run. Since our application needs more than 256 MB of memory (default value), it was deployed with 1 GB of memory. It is available in: https://image-xhfxku6nlq-uc.a.run.app"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BDCC_Report",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
